{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://danieltakeshi.github.io/2016/12/01/going-deeper-into-reinforcement-learning-understanding-dqn/\n",
    "- https://github.com/hengyuan-hu/rainbow\n",
    "- https://medium.com/mlreview/speeding-up-dqn-on-pytorch-solving-pong-in-30-minutes-81a1bd2dff55\n",
    "- https://github.com/transedward/pytorch-dqn\n",
    "- https://github.com/AndersonJo/dqn-pytorch\n",
    "**TODO**\n",
    "- Use 4 frames or frame difference instead of single frame\n",
    "- End of episode next states should have value of 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import cv2\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "    return gray\n",
    "\n",
    "def resize(img):\n",
    "    res = cv2.resize(img, dsize=(84, 84), interpolation=cv2.INTER_CUBIC)\n",
    "    return res\n",
    "\n",
    "def process_image(img):\n",
    "    return resize(rgb2gray(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 84)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4c409762e8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make('Breakout-v0')\n",
    "observation = env.reset()\n",
    "processed = resize(rgb2gray(observation))\n",
    "print(processed.shape)\n",
    "plt.imshow(processed, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOOP', 'FIRE', 'RIGHT', 'LEFT']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.unwrapped.get_action_meanings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.head = nn.Linear(1568, 4) #6 actions from from env.action_space.n\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        #print(x.shape)\n",
    "        return self.head(x.view(x.size(0), -1)) #flattens the (N, C, H, W) to (N, C*H*W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQN(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(2, 2))\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(2, 2))\n",
       "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(32, 32, kernel_size=(5, 5), stride=(2, 2))\n",
       "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (head): Linear(in_features=1568, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DQN().to(device)\n",
    "target = DQN().to(device)\n",
    "target.load_state_dict(model.state_dict())\n",
    "target.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_model(buffer):\n",
    "    \n",
    "    BATCH_SIZE = 32\n",
    "    \n",
    "    random.shuffle(buffer)\n",
    "    \n",
    "    states, next_states, actions, rewards = zip(*buffer)\n",
    "    \n",
    "    states = torch.stack(states).squeeze(1)\n",
    "    next_states = torch.stack(next_states).squeeze(1)\n",
    "    \n",
    "    actions = torch.LongTensor(actions).to(device)\n",
    "    rewards = torch.FloatTensor(rewards).to(device)\n",
    "        \n",
    "    n_batches = len(buffer) // BATCH_SIZE\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        \n",
    "        batch_states = states[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
    "        batch_next_states = next_states[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
    "        batch_actions = actions[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
    "        batch_rewards = rewards[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
    "        \n",
    "        Qsa = model(batch_states)\n",
    "        \n",
    "        pred_values, pred_actions = Qsa.topk(1)\n",
    "        \n",
    "        exp_Qsa = target(batch_next_states)\n",
    "        \n",
    "        #print(exp_Qsa)\n",
    "        target_Qsa = exp_Qsa.max(1)[0] #get max Q values\n",
    "        \n",
    "        #assert 1 == 2\n",
    "        \n",
    "        #print(exp_Qsa.shape)\n",
    "        #print(batch_rewards.shape)\n",
    "        \n",
    "        #print(target_Qsa.shape)\n",
    "        \n",
    "        #print(batch_rewards.shape)\n",
    "        \n",
    "        target_Qsa = (target_Qsa * 0.99) + batch_rewards\n",
    "        \n",
    "        #print(pred_values.shape)\n",
    "        #print(target_Qsa.shape)\n",
    "        \n",
    "        loss = F.smooth_l1_loss(pred_values.squeeze(1), target_Qsa.detach())\n",
    "        \n",
    "        #assert 1 == 2\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        for p in model.parameters():\n",
    "            p.grad.data.clamp(-1, 1)\n",
    "            \n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0100, Episode Reward: 4.0, Episode Frames: 598, Total Frames: 175780, Epsilon: 0.83, Action Count: [70, 80, 148, 87]\n",
      "Episode: 0200, Episode Reward: 4.0, Episode Frames: 1270, Total Frames: 359055, Epsilon: 0.65, Action Count: [57, 68, 243, 69]\n",
      "Episode: 0300, Episode Reward: 2.0, Episode Frames: 1252, Total Frames: 545324, Epsilon: 0.46, Action Count: [36, 36, 198, 35]\n"
     ]
    }
   ],
   "source": [
    "N_EPISODES = 2500\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "episode = 1\n",
    "buffer = []\n",
    "rewards_per_episode = []\n",
    "total_frames = 0\n",
    "start_epsilon = 1\n",
    "end_epsilon = 0.01\n",
    "epsilon_steps = 1_000_000\n",
    "e = np.linspace(start_epsilon, end_epsilon, epsilon_steps)\n",
    "\n",
    "\n",
    "while True:\n",
    "\n",
    "    \n",
    "    env = gym.make('Breakout-v0')\n",
    "    act_count = [0, 0, 0, 0]\n",
    "    episode_reward = 0\n",
    "    \n",
    "\n",
    "    state = env.reset()\n",
    "\n",
    "    state = torch.from_numpy(process_image(state)).float().unsqueeze(0).unsqueeze(0).to(device)\n",
    "    \n",
    "    while True:\n",
    "\n",
    "        epsilon = e[total_frames] if total_frames < len(e) else end_epsilon\n",
    "        \n",
    "        if random.random() > epsilon:\n",
    "            action = model(state)\n",
    "            _, idx = torch.topk(action, 1)\n",
    "            action = idx.item()\n",
    "        else:\n",
    "            action = env.action_space.sample()\n",
    "            \n",
    "        act_count[action] += 1\n",
    "        \n",
    "        next_state, reward, done, info = env.step(action)\n",
    "\n",
    "        next_state = torch.from_numpy(process_image(next_state)).float().unsqueeze(0).unsqueeze(0).to(device)\n",
    "        \n",
    "        buffer.append((state, next_state, action, reward))\n",
    "\n",
    "        episode_reward += reward\n",
    "\n",
    "        if done:\n",
    "            #rewards_per_episode.append(episode_reward)\n",
    "            episode += 1\n",
    "            break\n",
    "            \n",
    "    total_frames += len(buffer)\n",
    "    \n",
    "    if episode % 100 == 0:\n",
    "        print(f'Episode: {episode:04}, Episode Reward: {episode_reward}, Episode Frames: {len(buffer)}, Total Frames: {total_frames}, Epsilon: {epsilon:.02f}, Action Count: {act_count}')\n",
    "            \n",
    "    if len(buffer) > BATCH_SIZE * 100:\n",
    "        update_model(buffer)\n",
    "        buffer = []\n",
    "    \n",
    "    if episode % 1000 == 0:\n",
    "        target.load_state_dict(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
