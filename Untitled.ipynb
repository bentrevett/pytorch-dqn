{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import timeit\n",
    "import gym\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "from datetime import timedelta\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.99\n",
    "LR = 1e-4\n",
    "TARGET_NET_UPDATE_FREQ = 1_000\n",
    "EXP_REPLAY_SIZE = 10_0000\n",
    "BATCH_SIZE = 32\n",
    "LEARN_START = 10_000\n",
    "MAX_FRAMES= 1_000_000\n",
    "\n",
    "epsilon_start = 1.0\n",
    "epsilon_final = 0.01\n",
    "epsilon_decay = 30_000\n",
    "epsilon_by_frame = lambda frame_idx: epsilon_final + (epsilon_start - epsilon_final) * math.exp(-1. * frame_idx / epsilon_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoopResetEnv(gym.Wrapper):\n",
    "    def __init__(self, env, noop_max=30):\n",
    "        \"\"\"Sample initial states by taking random number of no-ops on reset.\n",
    "        No-op is assumed to be action 0.\n",
    "        \"\"\"\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        self.noop_max = noop_max\n",
    "        self.override_num_noops = None\n",
    "        self.noop_action = 0\n",
    "        assert env.unwrapped.get_action_meanings()[0] == 'NOOP'\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        \"\"\" Do no-op action for a number of steps in [1, noop_max].\"\"\"\n",
    "        self.env.reset(**kwargs)\n",
    "        if self.override_num_noops is not None:\n",
    "            noops = self.override_num_noops\n",
    "        else:\n",
    "            noops = self.unwrapped.np_random.randint(1, self.noop_max + 1) \n",
    "        assert noops > 0\n",
    "        obs = None\n",
    "        for _ in range(noops):\n",
    "            obs, _, done, _ = self.env.step(self.noop_action)\n",
    "            if done:\n",
    "                obs = self.env.reset(**kwargs)\n",
    "        return obs\n",
    "\n",
    "    def step(self, ac):\n",
    "        return self.env.step(ac)\n",
    "    \n",
    "class MaxAndSkipEnv(gym.Wrapper):\n",
    "    def __init__(self, env, skip=4):\n",
    "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        # most recent raw observations (for max pooling across time steps)\n",
    "        self._obs_buffer = np.zeros((2,)+env.observation_space.shape, dtype=np.uint8)\n",
    "        self._skip       = skip\n",
    "\n",
    "    def reset(self):\n",
    "        return self.env.reset()\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Repeat action, sum reward, and max over last observations.\"\"\"\n",
    "        total_reward = 0.0\n",
    "        done = None\n",
    "        for i in range(self._skip):\n",
    "            obs, reward, done, info = self.env.step(action)\n",
    "            if i == self._skip - 2: self._obs_buffer[0] = obs\n",
    "            if i == self._skip - 1: self._obs_buffer[1] = obs\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        # Note that the observation on the done=True frame\n",
    "        # doesn't matter\n",
    "        max_frame = self._obs_buffer.max(axis=0)\n",
    "\n",
    "        return max_frame, total_reward, done, info\n",
    "\n",
    "    def reset(self, **kwargs): \n",
    "        return self.env.reset(**kwargs)\n",
    "    \n",
    "class FireResetEnv(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        \"\"\"Take action on reset for environments that are fixed until firing.\"\"\"\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        assert env.unwrapped.get_action_meanings()[1] == 'FIRE'\n",
    "        assert len(env.unwrapped.get_action_meanings()) >= 3\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        self.env.reset(**kwargs)\n",
    "        obs, _, done, _ = self.env.step(1)\n",
    "        if done:\n",
    "            self.env.reset(**kwargs)\n",
    "        obs, _, done, _ = self.env.step(2)\n",
    "        if done:\n",
    "            self.env.reset(**kwargs)\n",
    "        return obs\n",
    "\n",
    "    def step(self, ac):\n",
    "        return self.env.step(ac)\n",
    "\n",
    "class EpisodicLifeEnv(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        \"\"\"Make end-of-life == end-of-episode, but only reset on true game over.\n",
    "        Done by DeepMind for the DQN and co. since it helps value estimation.\n",
    "        \"\"\"\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        self.lives = 0\n",
    "        self.was_real_done  = True\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, done, info = self.env.step(action)\n",
    "        self.was_real_done = done\n",
    "        # check current lives, make loss of life terminal,\n",
    "        # then update lives to handle bonus lives\n",
    "        lives = self.env.unwrapped.ale.lives()\n",
    "        if lives < self.lives and lives > 0:\n",
    "            # for Qbert sometimes we stay in lives == 0 condtion for a few frames\n",
    "            # so its important to keep lives > 0, so that we only reset once\n",
    "            # the environment advertises done.\n",
    "            done = True\n",
    "        self.lives = lives\n",
    "        return obs, reward, done, info\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        \"\"\"Reset only when lives are exhausted.\n",
    "        This way all states are still reachable even though lives are episodic,\n",
    "        and the learner need not know about any of this behind-the-scenes.\n",
    "        \"\"\"\n",
    "        if self.was_real_done:\n",
    "            obs = self.env.reset(**kwargs)\n",
    "        else:\n",
    "            # no-op step to advance from terminal/lost life state\n",
    "            obs, _, _, _ = self.env.step(0)\n",
    "        self.lives = self.env.unwrapped.ale.lives()\n",
    "        return obs\n",
    "    \n",
    "class WarpFrame(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        \"\"\"Warp frames to 84x84 as done in the Nature paper and later work.\"\"\"\n",
    "        gym.ObservationWrapper.__init__(self, env)\n",
    "        self.width = 84\n",
    "        self.height = 84\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255,\n",
    "            shape=(self.height, self.width, 1), dtype=np.uint8)\n",
    "\n",
    "    def observation(self, frame):\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        frame = cv2.resize(frame, (self.width, self.height), interpolation=cv2.INTER_AREA)\n",
    "        return frame[:, :, None]\n",
    "    \n",
    "class ClipRewardEnv(gym.RewardWrapper):\n",
    "    def __init__(self, env):\n",
    "        gym.RewardWrapper.__init__(self, env)\n",
    "\n",
    "    def reward(self, reward):\n",
    "        \"\"\"Bin reward to {+1, 0, -1} by its sign.\"\"\"\n",
    "        return np.sign(reward)\n",
    "\n",
    "class LazyFrames(object):\n",
    "    def __init__(self, frames):\n",
    "        \"\"\"This object ensures that common frames between the observations are only stored once.\n",
    "        It exists purely to optimize memory usage which can be huge for DQN's 1M frames replay\n",
    "        buffers.\n",
    "        This object should only be converted to numpy array before being passed to the model.\n",
    "        You'd not believe how complex the previous solution was.\"\"\"\n",
    "        self._frames = frames\n",
    "        self._out = None\n",
    "\n",
    "    def _force(self):\n",
    "        if self._out is None:\n",
    "            self._out = np.concatenate(self._frames, axis=2)\n",
    "            self._frames = None\n",
    "        return self._out\n",
    "\n",
    "    def __array__(self, dtype=None):\n",
    "        out = self._force()\n",
    "        if dtype is not None:\n",
    "            out = out.astype(dtype)\n",
    "        return out\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._force())\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self._force()[i]    \n",
    "    \n",
    "class FrameStack(gym.Wrapper):\n",
    "    def __init__(self, env, k):\n",
    "        \"\"\"Stack k last frames.\n",
    "        Returns lazy array, which is much more memory efficient.\n",
    "        See Also\n",
    "        --------\n",
    "        baselines.common.atari_wrappers.LazyFrames\n",
    "        \"\"\"\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        self.k = k\n",
    "        self.frames = deque([], maxlen=k)\n",
    "        shp = env.observation_space.shape\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(shp[0], shp[1], shp[2] * k), dtype=np.uint8)\n",
    "\n",
    "    def reset(self):\n",
    "        ob = self.env.reset()\n",
    "        for _ in range(self.k):\n",
    "            self.frames.append(ob)\n",
    "        return self._get_ob()\n",
    "\n",
    "    def step(self, action):\n",
    "        ob, reward, done, info = self.env.step(action)\n",
    "        self.frames.append(ob)\n",
    "        return self._get_ob(), reward, done, info\n",
    "\n",
    "    def _get_ob(self):\n",
    "        assert len(self.frames) == self.k\n",
    "        return LazyFrames(list(self.frames))\n",
    "\n",
    "def make_atari(env_id):\n",
    "    env = gym.make(env_id)\n",
    "    assert 'NoFrameskip' in env.spec.id\n",
    "    env = NoopResetEnv(env, noop_max=30)\n",
    "    env = MaxAndSkipEnv(env, skip=4)\n",
    "    return env\n",
    "\n",
    "def wrap_deepmind(env, episode_life=True, clip_rewards=True, frame_stack=False, scale=False):\n",
    "    \"\"\"Configure environment for DeepMind-style Atari.\n",
    "    \"\"\"\n",
    "    if episode_life:\n",
    "        env = EpisodicLifeEnv(env)\n",
    "    if 'FIRE' in env.unwrapped.get_action_meanings():\n",
    "        env = FireResetEnv(env)\n",
    "    env = WarpFrame(env)\n",
    "    if scale:\n",
    "        env = ScaledFloatFrame(env)\n",
    "    if clip_rewards:\n",
    "        env = ClipRewardEnv(env)\n",
    "    if frame_stack:\n",
    "        env = FrameStack(env, 4)\n",
    "    return env\n",
    "\n",
    "\n",
    "class ImageToPyTorch(gym.ObservationWrapper):\n",
    "    \"\"\"\n",
    "    Image shape to num_channels x weight x height\n",
    "    \"\"\"\n",
    "    def __init__(self, env):\n",
    "        super(ImageToPyTorch, self).__init__(env)\n",
    "        old_shape = self.observation_space.shape\n",
    "        self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=(old_shape[-1], old_shape[0], old_shape[1]), dtype=np.uint8)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return np.swapaxes(observation, 2, 0)\n",
    "    \n",
    "def wrap_pytorch(env):\n",
    "    return ImageToPyTorch(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperienceReplayMemory:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "\n",
    "    def push(self, transition):\n",
    "        self.memory.append(transition)\n",
    "        if len(self.memory) > self.capacity:\n",
    "            del self.memory[0]\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_shape, num_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.num_actions = num_actions\n",
    "\n",
    "        self.conv1 = nn.Conv2d(self.input_shape[0], 32, kernel_size=8, stride=4)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.feature_size(), 512)\n",
    "        self.fc2 = nn.Linear(512, self.num_actions)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def feature_size(self):\n",
    "        return self.conv3(self.conv2(self.conv1(torch.zeros(1, *self.input_shape)))).view(1, -1).size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, static_policy=False, env=None):\n",
    "        super(Model, self).__init__()\n",
    "        self.gamma=GAMMA\n",
    "        self.lr = LR\n",
    "        self.target_net_update_freq = TARGET_NET_UPDATE_FREQ\n",
    "        self.experience_replay_size = EXP_REPLAY_SIZE\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        self.learn_start = LEARN_START\n",
    "\n",
    "        self.static_policy=static_policy\n",
    "        self.num_feats = env.observation_space.shape\n",
    "        self.num_actions = env.action_space.n\n",
    "        self.env = env\n",
    "\n",
    "        self.declare_networks()\n",
    "            \n",
    "        self.target_model.load_state_dict(self.model.state_dict())\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        \n",
    "        #move to correct device\n",
    "        self.model = self.model.to(device)\n",
    "        self.target_model.to(device)\n",
    "\n",
    "        if self.static_policy:\n",
    "            self.model.eval()\n",
    "            self.target_model.eval()\n",
    "        else:\n",
    "            self.model.train()\n",
    "            self.target_model.train()\n",
    "\n",
    "        self.update_count = 0\n",
    "\n",
    "        self.declare_memory()\n",
    "        \n",
    "\n",
    "    def declare_networks(self):\n",
    "        self.model = DQN(self.num_feats, self.num_actions)\n",
    "        self.target_model = DQN(self.num_feats, self.num_actions)\n",
    "\n",
    "    def declare_memory(self):\n",
    "        self.memory = ExperienceReplayMemory(self.experience_replay_size)\n",
    "\n",
    "    def append_to_replay(self, s, a, r, s_):\n",
    "        self.memory.push((s, a, r, s_))\n",
    "\n",
    "\n",
    "    def prep_minibatch(self):\n",
    "        # random transition batch is taken from experience replay memory\n",
    "        transitions = self.memory.sample(BATCH_SIZE)\n",
    "        \n",
    "        batch_state, batch_action, batch_reward, batch_next_state = zip(*transitions)\n",
    "\n",
    "        shape = (-1,)+self.num_feats\n",
    "\n",
    "        batch_state = torch.tensor(batch_state, device=device, dtype=torch.float).view(shape)\n",
    "        batch_action = torch.tensor(batch_action, device=device, dtype=torch.long).squeeze().view(-1, 1)\n",
    "        batch_reward = torch.tensor(batch_reward, device=device, dtype=torch.float).squeeze().view(-1, 1)\n",
    "        \n",
    "        non_final_mask = torch.tensor(tuple(map(lambda s: s is not None, batch_next_state)), device=device, dtype=torch.uint8)\n",
    "        try: #sometimes all next states are false\n",
    "            non_final_next_states = torch.tensor([s for s in batch_next_state if s is not None], device=device, dtype=torch.float).view(shape)\n",
    "            empty_next_state_values = False\n",
    "        except:\n",
    "            non_final_next_states = None\n",
    "            empty_next_state_values = True\n",
    "            \n",
    "        return batch_state, batch_action, batch_reward, non_final_next_states, non_final_mask, empty_next_state_values\n",
    "\n",
    "    def compute_loss(self, batch_vars):\n",
    "        batch_state, batch_action, batch_reward, non_final_next_states, non_final_mask, empty_next_state_values = batch_vars\n",
    "\n",
    "        #estimate\n",
    "        current_q_values = self.model(batch_state).gather(1, batch_action)\n",
    "        \n",
    "        #target\n",
    "        with torch.no_grad():\n",
    "            max_next_q_values = torch.zeros(self.batch_size, device=device, dtype=torch.float).unsqueeze(dim=1)\n",
    "            if not empty_next_state_values:\n",
    "                max_next_action = self.get_max_next_state_action(non_final_next_states)\n",
    "                max_next_q_values[non_final_mask] = self.target_model(non_final_next_states).gather(1, max_next_action)\n",
    "            expected_q_values = batch_reward + (self.gamma*max_next_q_values)\n",
    "\n",
    "        diff = (expected_q_values - current_q_values)\n",
    "        loss = self.huber(diff)\n",
    "        loss = loss.mean()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def update(self, s, a, r, s_, frame=0):\n",
    "        if self.static_policy:\n",
    "            return None\n",
    "\n",
    "        self.append_to_replay(s, a, r, s_)\n",
    "\n",
    "        if frame < self.learn_start:\n",
    "            return None\n",
    "\n",
    "        batch_vars = self.prep_minibatch()\n",
    "\n",
    "        loss = self.compute_loss(batch_vars)\n",
    "\n",
    "        # Optimize the model\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        for param in self.model.parameters():\n",
    "            param.grad.data.clamp_(-1, 1)\n",
    "        self.optimizer.step()\n",
    "\n",
    "        self.update_target_model()\n",
    "        return loss.item()\n",
    "\n",
    "\n",
    "    def get_action(self, s, eps=0.1):\n",
    "        with torch.no_grad():\n",
    "            if np.random.random() >= eps or self.static_policy:\n",
    "                X = torch.tensor([s], device=device, dtype=torch.float)\n",
    "                a = self.model(X).max(1)[1].view(1, 1)\n",
    "                return a.item()\n",
    "            else:\n",
    "                return np.random.randint(0, self.num_actions)\n",
    "\n",
    "    def update_target_model(self):\n",
    "        self.update_count+=1\n",
    "        self.update_count = self.update_count % self.target_net_update_freq\n",
    "        if self.update_count == 0:\n",
    "            self.target_model.load_state_dict(self.model.state_dict())\n",
    "\n",
    "    def get_max_next_state_action(self, next_states):\n",
    "        return self.target_model(next_states).max(dim=1)[1].view(-1, 1)\n",
    "\n",
    "    def huber(self, x):\n",
    "        cond = (x.abs() < 1.0).to(torch.float)\n",
    "        return 0.5 * x.pow(2) * cond + (x.abs() - 0.5) * (1 - cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards, losses, elapsed_time):\n",
    "    display.clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s. time: %s' % (frame_idx, np.mean(rewards[-10:]), elapsed_time))\n",
    "    plt.plot(rewards)\n",
    "    plt.subplot(132)\n",
    "    plt.title('loss')\n",
    "    plt.plot(losses)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-5031f22b3c1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_observation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mepisode_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-a20081de4aed>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, s, a, r, s_, frame)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mbatch_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep_minibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-a20081de4aed>\u001b[0m in \u001b[0;36mprep_minibatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_feats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mbatch_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mbatch_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mbatch_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start=timeit.default_timer()\n",
    "\n",
    "env_id = \"PongNoFrameskip-v4\"\n",
    "env    = make_atari(env_id)\n",
    "env    = wrap_deepmind(env, frame_stack=True)\n",
    "env    = wrap_pytorch(env)\n",
    "model = Model(env=env)\n",
    "\n",
    "losses = []\n",
    "all_rewards = []\n",
    "episode_reward = 0\n",
    "\n",
    "observation = env.reset()\n",
    "for frame_idx in range(1, MAX_FRAMES + 1):\n",
    "    epsilon = epsilon_by_frame(frame_idx)\n",
    "\n",
    "    action = model.get_action(observation, epsilon)\n",
    "    prev_observation=observation\n",
    "    observation, reward, done, _ = env.step(action)\n",
    "    observation = None if done else observation\n",
    "\n",
    "    loss = model.update(prev_observation, action, reward, observation, frame_idx)\n",
    "    episode_reward += reward\n",
    "\n",
    "    if done:\n",
    "        observation = env.reset()\n",
    "        all_rewards.append(episode_reward)\n",
    "        episode_reward = 0\n",
    "        \n",
    "        if np.mean(all_rewards[-10:]) > 19:\n",
    "            plot(frame_idx, all_rewards, losses, timedelta(seconds=int(timeit.default_timer()-start)))\n",
    "            break\n",
    "\n",
    "    if loss is not None:\n",
    "        losses.append(loss)\n",
    "\n",
    "    if frame_idx % 10000 == 0:\n",
    "        plot(frame_idx, all_rewards, losses, timedelta(seconds=int(timeit.default_timer()-start)))\n",
    "\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
